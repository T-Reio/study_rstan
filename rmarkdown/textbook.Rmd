---
title: "Studying R Stan"
author: "R. Tanji"
date: ""
output: 
  html_document:
    toc: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(pacman)
library(tidyverse)
```

## Chap 1 統計モデリングとStanの概要

### 統計モデリングとは

-   世の中の事象を、必要なエッセンスだけ取り出して描写すること

    -   プラモデル：色や形を残して材質・機能を捨象

-   数式を用いてエッセンスを記述する：数理モデル

    -   確率モデル probabilistic model

-   統計モデリング：確率モデルをデータに当てはめて、現象の理解と予測を促す

    -   統計モデリングの要素

        -   確率分布

        -   パラメータ

        -   パラメータをつなぐ関係式

-   モデル化にあたって捨象した要素の重要性を確認する

### 統計モデリングの目的

統計モデルの2つの目的

-   解釈

    -   データの生成過程を理解する

    -   解釈可能なモデルをもとに、次のアクションを決める

-   予測

**頑健性**：解釈可能で予測精度の高いモデル

-   機械学習との違い：SVM: サポートベクターマシン、勾配ブースティング、ランダムフォレスト、...

    -   数式をモデリングするための背景知識が少なくても予測可能

    -   過学習が起こりやすい

-   古典的な分散分析、グループごとの集計との違い

    -   直感的で解釈しやすい

    -   対象に対する背景知識や経験を活用しきれない

→両者の性能を併せ持つ手法としての統計モデリング

### 確率的プログラミング言語

-   確率モデルのパラメータ推定における難点

    -   推定計算の数式導出

    -   モデルの変化に対応した数値計算の実装

-   プログラミング言語の登場により、これらの操作がより平易に

    -   多数のモデルを試行錯誤可能に

### なぜStanなのか

-   これまで主流だったソフトウェア

    -   WinBUGS

    -   JAGS

-   **Stan**

    -   RStan

    -   PythonやMATLABとも連携可能

    -   **NUTS**: No-U-Turn Sampler

        -   Hamiltonian Monte Carlo (HMC, MCMCの一種)の実装

        -   パラメータの数が多い場合の効率的なサンプリング

        -   1ステップあたりの所要時間はその他の言語に比べて長いが、ステップ間の相関が低いため、従来よりも少ないステップで計算を完了することができる

        -   複雑なモデルのサンプリングも可能

    -   その他、デバッグのしやすさ、マニュアルの詳細さなどの長所

### なぜRStanなのか

-   Stanの性能とRの優れた可視化機能を連結

-   確率分布を使うモデルが容易に実装可能

-   データ加工も容易

## Chap2 ベイズ推定の復習

### 基本用語と記法

-   確率分布

    -   確率変数$a$の確率分布$p(a)$

-   確率質量関数: probability mass function

    -   離散値を取る確率変数の分布

-   確率密度関数: probability density function

    -   連続地を取る確率変数の分布

-   同時分布・結合分布: joint distribution

    -   複数個の確率変数が取りうる各の値の組に対して、その起こりやすさを確率で表現したもの

    -   $k$個の確率変数$\theta_1, \theta_2, \ldots, \theta_k$の同時分布：$p(\theta_1, \theta_2, \ldots, \theta_k)$

-   周辺化: marginalization

    -   同時分布から特定の確率変数について、その和を取る(離散)または積分する(連続)ことで、その変数を消去すること

    -   2変数$a, b$の同時分布$p(a, b)に$おいて、$aに$ついて和を取ることで周辺分布$p(b)が$求まる

        -   離散値: $p(b) = \sum_a p(a, b)$

        -   連続値: $p(b) = \int p(a, b)da$

-   条件付確率分布: conditional distribution

    -   同時分布\$p(a, b)に\$ついて、ある\$b = b_0\$が与えられたときの確率変数$a$の分布

    -   \$p(a \| b_0) = \dfrac{p(a, b_0)}{p(b_0)}\$

    -   パラメータ$\theta$について条件づける時も同様

-   $y \sim p(y)$

    -   確率変数$yが$分布$p(y)に$従う

-   正規化

    -   関数の和・積分が1になるように、その関数に定数を掛けること

        -   正規化定数・規格化定数

-   偏微分

    -   多変数関数$f(\theta_1, \ldots, \theta_k)に$ついて

    -   $$
        \lim_{\Delta \theta_1 \to 0}\dfrac{f(\theta_1 + \Delta\theta_1, \ldots, \theta_k) - f(\theta_1, \ldots, \theta_k)}{\Delta \theta_1}
        $$

-   大文字から始まるアルファベット

    -   観測されたデータを表す

-   ベクトルと行列

    -   ベクトルは$\overset{\to}{x}$, 行列は$\mathbf{x}$で表現する

-   添え字と[]

    -   察せ

### 伝統的な統計学(頻度論)の問題点

-   伝統的な統計学：パラメータ$\thetaが$ある一点の真値をもつ定数と考える

-   実用上の問題

    -   検定の解釈が直感的でない

    -   信頼区間の解釈が直感的でない

    -   複雑なモデルにおいて、信頼区間と予測区間の算出が難しい

### 尤度と最尤推定

モデルのあてはまりの評価

定式化されたモデル：「$Y[n] (n = 1, \ldots, 20)$は、$\text{Normal}(\mu, 1)に$従う」...推定すべきパラメータは$\mu$である

-   尤度: likelihood

    -   パラメータ$\mu$に対する尤度関数：

    -   $$
        L(\mu) = \prod_{n = 1}^N \text{Normal}(Y[n] | \mu, 1)
        $$

    -   パラメータに条件づけたときのデータ$Y$が観測される確率

-   尤度が最も高くなるパラメータを探す推定法を最尤推定(maximum likelihood estimation)と呼ぶ

    -   推定値：maximum likelihood estimate

    -   **パラメータは点推定される**

-   一般に、尤度は1未満の多数の数の積であるため、非常に小さな値を持つ。そのため、計算の煩雑さを避けるために対数を取る(対数尤度)

    -   Rの`optim`関数や`{nlme}`パッケージに含まれる関数では、適当にパラメータの初期値を与え、その位置から対数尤度が最も大きく増加する方向にパラメータを動かし、収束するまで繰り返すステップで推定を行う

**最尤推定が対処しきれない問題**

-   過学習(overfitting)

    -   (各グループごとの)観測が少数のサンプルに対する過剰な適合が経験に反する推定を正当化し、汎化性能(新しいデータに対する予測能力)を低下させる

-   最尤推定の実際の計算が難しくなる

    -   局所最適化が帯域最適化にならない可能性

    -   複数の初期値から推定を行うことである程度解決されるが、一方でパラメータが多数に及ぶ場合、十分な試行回数を稼ぐことが難しくなる

### ベイズ推定とMCMC

前節の問題を解決する方法の一つとして、

-   ベイズ推定 Bayesian Inference

-   マルコフ連鎖モンテカルロ法 Markov chain Monte Carlo methods

ベイズ推定では、すべてのパラメータを確率変数とみなして、その確率分布を想定する

-   特定のパラメータがある区間に入る確率を求める：直感的に解釈しやすい結果

    -   パラメータの点推定ではなく、あるデータ$Yが$得られたときの分布$p(\theta | Y)$ が得られる：複数パラメータの場合は同時分布

**事後分布：posterior distribution**

-   データ$Y$が得られた後の分布$p(\theta | Y)$

    -   事前分布$p(\theta)$

-   事後確率は、ベイズの定理より

-   $$
    p(\theta | Y) = \dfrac{p(Y | \theta) p(\theta)}{p(Y)} \propto p(Y | \theta)p(\theta)
    $$

    -   分母$p(Y)は$パラメータに依存せず、得られたデータ$Y$によってのみ決まる：パラメータ$\theta$のp(Y)は\$パラメータに依存せず、得られたデータ$Y$によってのみ決まる：パラメータ$\theta$の分布形は分子から作られ、分母はその正規化定数とみなせる
    -   分母の計算は容易でないため、分子の部分から乱数を発生させて事後分布に代替すれば、様々な統計量や積分計算を行うことができる：MCMC
        -   MCMCによって得られた乱数サンプルをMCMCサンプルと呼ぶ
    -   MCMCサンプルを生成するアルゴリズム
        -   メトロポリス・ヘイスティングス法 Metropolis-Hastings algorithm

        -   ギブスサンプリング Gibbs sampling

MCMCサンプルを用いたアルゴリズムの手順

1.  パラメータの初期値を適当に定めてMCMCサンプルを作成
2.  MCMCサンプルから得られたパラメータの推定値をもとに、次のステップのMCMCサンプルを乱数によって作成
3.  ステップからサンプルを得るごとにパラメータの値を更新していく

-   Glossary

    -   サンプル列：ステップ数に従って得られる値の系列

    -   chain：初期値と乱数のシードを一つに定めたときに得られたサンプル列

    -   トレースプロット：MCMCサンプルのパラメータの値を取った折れ線グラフ

    -   バーンイン burn in

        -   初期値直後のサンプル列：初期値への依存が大きいため、あえてサンプリングせずに捨てる

        -   密度分布は、例えば200ステップ経過した後のパラメータのMCMCサンプルから作成する：事後分布

    -   当然分布が収束しないこともある

        -   典型的にはサンプル列の自己相関が高くなっている

        -   数ステップ中の値が次のステップの値に大きな影響を与えているため、実質的に新しいサンプリングが行われていない

        -   影響が軽微な場合は、**thinning** (ステップすべてをサンプリングせず、数回に1度だけサンプリングを行う)ことで収束可能性が改善されることがある

        -   収束していない分布をもとに解析を進めることは基本的に推奨されない

            -   再現性問題

### ベイズ信頼区間とベイズ予測区間

### 最尤推定とベイズ推定との関係

### 事前分布の選択

## Chap 3

### データ解析の前準備

### 統計モデリングの手順

### モデルの記述方法

### 情報量基準を使ったモデル選択

## Chap 4 StanとRStanをはじめよう

### StanとRStanの準備

-   Rtoolsのインストール

    -   内部でC++を利用、そのコンパイラが必要になる

    -   PATH通しとく

-   起動

    ```{r}
    #install.packages("rstan")
    p_load(rstan)
    ```

### Stanの基本的な文法

以降、chap3.stanも参照してくれ

#### ブロック構成

```{stan, output.var="hoge", eval=FALSE}
data {
  データYの宣言
}

parameters {
  サンプリングしたいパラメータ\thetaの宣言
}

model {
  尤度関数p(Y|\theta)の記述
  事前分布p(\theta)の記述
}
```

-   各ブロックの中に情報を記述

-   値が決まっていない確率変数はすべてパラメータとして扱われる

-   サンプリングのシステム

    -   コードの実行→モデル式がC++のコードに変換され、コンパイルされてMCMCサンプリングが実行される

    -   ブロックの順序を誤るとエラーが出るので注意

#### 文法の基礎

-   標準偏差の定まった：正規分布をデータに当てはめる問題

-   モデル式4-1

$$
\begin{align}
Y[n] & \sim \text{Normal}(\mu, 1) \text{ where } n = 1, \ldots, N \\
\mu & \sim \text{Normal}(0, 100)
\end{align}
$$ - $N$は観測数に対応

-   未知のパラメータ$\mu$をデータから推定する

    -   無情報事前分布：平均ゼロ、標準偏差100の非常に平らな正規分布

-   Stanコードによる表現

```{stan, output.var="model4_1", eval=FALSE}
data {
  int N;
  real Y[N];
}

parameters {
  real mu;
}

model {
  for (n in 1:N) {
  Y[n] ~ normal(mu, 1);
  }
  mu ~ normal(0, 100)
}
```

-   dataブロック：データの個数Nと観測されたデータYを宣言

    -   int, realなどで変数のクラスを表現

    -   `Y[1], Y[2], …, Y[N]`：観測単位

-   modelブロック：事前分布の宣言: `mu ~ normal(0, 100)`

    -   forループで繰り返しデータを抽出することを表現
    -   特に指定がない場合、十分に幅の広い一様分布が使用される

-   parametersブロック：推定するパラメータを宣言

-   その他

    -   コメントアウト：`//`か`/**/`で囲む(後者は複数行を挟める)

    -   `#`は非推奨だが使えるらしい

    -   文法：BUGS言語と一部に違い、知らんからいい

#### コーディング規約

まあ変なことしなきゃいいんだけどね

1.  インテンドちゃんとする
2.  データの変数は大文字、パラメータを小文字で表現
3.  ブロック間は1行空けて
4.  変数名は`_`でつなぐ(`snake_case`っていうらしい。対立概念に`camelCase`とか、まあRと一緒だな)
5.  `~=`の間はスペース入れろ

### Stanの`lp__`と`target`

Stanのパラメータ探索

-   事後確率$p(\theta | Y) \propto p(Y | \theta) p(\theta)p(\theta | Y)$の高くなるパラメータを探す
-   効率を上げるために、実際には対数事後確率を見る $$
      \log p(\theta | Y) \propto \log p(Y | \theta)  + \log p(\theta) + \text{constant}
      $$
-   対数事後確率をパラメータ$\theta$について偏微分した値によって決める
    -   このため、各MCMCステップのパラメータ$\theta^*$におけるt対数事後確率の定数項以外の項：$\log p(Y | \theta^*) + \log p(\theta^*)$を保持しておく$=$`lp__`：log posterior という名前で保持している
    -   尤度と事前分布の記述によって`lp__`の関数形が決まる
-   `target`
    -   `lp__`$=\log p(Y | \theta^*)+\log p(\theta^*)$

    -   サンプリングのプロセスにおいては、事前確率$\log(\theta^*)$に対して、尤度$\log p(Y|\theta)$ を(観測単位ごとに)繰り返し足し続けることになる

    -   このプロセスを明示的に表現した記法: 2つの記述は同値になる

        ```{stan, output.var='model4_3', eval=FALSE}
        model {
          for (n in 1:N) {
            Y[n] ~ normal(mu, 1);
          }
          mu ~ normal(0, 100)
        }
        ```

        ```{stan, output.var='model4_3_2', eval=FALSE}
        model {
          for (n in 1:N) {
            target += normal_lpdf(Y[n] | mu, 1);
            /* target += x はtarget = target + x と同値
            /* N(mu, 1)からY[n]をドローする確率、N回分足し続ける：尤度 */
          }
          target += normal_lpdf(Y[n] | mu, 100)
          /* 事前分布 */
        }
        ```
-   高度な分析においては、あえて`target`を使った書き方が必要になることも

### 単回帰
